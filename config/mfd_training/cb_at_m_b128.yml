training:
  # Basic training parameters
  batch_size: 128
  final_epoch: 30
  learning_rate: 0.001
  random_seed: 2665
  scheduler: null

  # GPU configuration
  use_cuda: true
  gpu_setting: "0" # A string that is passed as an environment variable

  # Warning, these settings are for student model
  # Optional: Path for loading pre-trained model weights
  # load_path:
  # load_stats:
  # Path for saving model and performance data
  save_path: "/tmp2/pfe/mfd/cb_at_m_b128"

mfd:
  # path to the teacher model, assume it has the same structure as the students
  teacher_path: "/tmp2/pfe/model/cb_at_m_b64/checkpoint_epoch_0008.pth"
  lamda: 1.5

dataset:
  training_schema: 'mfd'
  name: 'celeba' # name of the dataset
  type: 'binary' # 'binary' or 'multi-class'; determines which fairness metrics are available
  balanced: true
  selected_attrs:
    - Attractive
  protected_attr: 'Male'
  task_name: 'Attractive'
  num_subgroups: 2